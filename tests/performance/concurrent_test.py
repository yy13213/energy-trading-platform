#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
èƒ½æºäº¤æ˜“å¹³å°å¹¶å‘æµ‹è¯•è„šæœ¬
æµ‹è¯•ç›®æ ‡ï¼šå¹¶å‘ç”¨æˆ·æ•° > 200
"""

import asyncio
import aiohttp
import time
import json
import statistics
from datetime import datetime
import csv
import os
from concurrent.futures import ThreadPoolExecutor
import threading

class ConcurrentTest:
    def __init__(self, base_url="http://127.0.0.1:8080"):
        self.base_url = base_url
        self.results = []
        self.active_users = 0
        self.max_concurrent_users = 0
        self.test_token = "test_token_for_concurrent_testing"
        self.lock = threading.Lock()
        
    async def simulate_user_session(self, session, user_id, session_duration=30):
        """æ¨¡æ‹Ÿå•ä¸ªç”¨æˆ·ä¼šè¯"""
        with self.lock:
            self.active_users += 1
            if self.active_users > self.max_concurrent_users:
                self.max_concurrent_users = self.active_users
        
        try:
            start_time = time.time()
            session_results = []
            
            # ç”¨æˆ·æ“ä½œåºåˆ— - ä½¿ç”¨ä¸éœ€è¦è®¤è¯çš„æ¥å£
            user_actions = [
                ('/cache_stats', 'GET', {}),
                ('/getAvailableEnergy', 'POST', {}),
                ('/get_items', 'POST', {}),
                ('/getUserAvailableEnergy', 'POST', {'user_address': f'test_user_{user_id}'}),
                ('/log_page_visit', 'POST', {'page': f'test_page_{user_id}', 'user_agent': 'test_agent'}),
            ]
            
            # åœ¨ä¼šè¯æœŸé—´é‡å¤æ‰§è¡Œæ“ä½œ
            while time.time() - start_time < session_duration:
                for endpoint, method, data in user_actions:
                    try:
                        result = await self.make_request(session, endpoint, method, data, user_id)
                        session_results.append(result)
                        
                        # æ¨¡æ‹Ÿç”¨æˆ·æ€è€ƒæ—¶é—´
                        await asyncio.sleep(0.1 + (user_id % 5) * 0.1)  # 0.1-0.6ç§’éšæœºé—´éš”
                        
                    except Exception as e:
                        session_results.append({
                            'user_id': user_id,
                            'endpoint': endpoint,
                            'method': method,
                            'response_time': 0,
                            'status': 0,
                            'success': False,
                            'error': str(e),
                            'timestamp': datetime.now().isoformat()
                        })
            
            return session_results
            
        finally:
            with self.lock:
                self.active_users -= 1
    
    async def make_request(self, session, endpoint, method, data, user_id):
        """å‘é€HTTPè¯·æ±‚"""
        # å¤§éƒ¨åˆ†æ¥å£ä¸éœ€è¦è®¤è¯ï¼Œåªè®¾ç½®åŸºæœ¬headers
        headers = {'Content-Type': 'application/json'}
        
        start_time = time.time()
        try:
            if method.upper() == "POST":
                async with session.post(f"{self.base_url}{endpoint}", 
                                      json=data, 
                                      headers=headers) as response:
                    await response.text()
                    status = response.status
            else:
                async with session.get(f"{self.base_url}{endpoint}", 
                                     headers=headers) as response:
                    await response.text()
                    status = response.status
                    
            end_time = time.time()
            response_time = end_time - start_time
            
            return {
                'user_id': user_id,
                'endpoint': endpoint,
                'method': method,
                'response_time': response_time,
                'status': status,
                'success': status < 400,
                'timestamp': datetime.now().isoformat()
            }
            
        except Exception as e:
            end_time = time.time()
            response_time = end_time - start_time
            return {
                'user_id': user_id,
                'endpoint': endpoint,
                'method': method,
                'response_time': response_time,
                'status': 0,
                'success': False,
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            }
    
    async def run_concurrent_test(self, target_users=250, ramp_up_time=30, test_duration=120):
        """è¿è¡Œå¹¶å‘æµ‹è¯•"""
        print(f"ğŸš€ å¼€å§‹å¹¶å‘æµ‹è¯•...")
        print(f"ğŸ“Š æµ‹è¯•å‚æ•°:")
        print(f"   ç›®æ ‡å¹¶å‘ç”¨æˆ·æ•°: {target_users}")
        print(f"   çˆ¬å¡æ—¶é—´: {ramp_up_time}ç§’")
        print(f"   æµ‹è¯•æŒç»­æ—¶é—´: {test_duration}ç§’")
        
        # é…ç½®è¿æ¥æ± 
        connector = aiohttp.TCPConnector(
            limit=target_users + 50,  # è¿æ¥æ± å¤§å°
            limit_per_host=target_users + 50,
            ttl_dns_cache=300
        )
        
        timeout = aiohttp.ClientTimeout(total=30)
        
        async with aiohttp.ClientSession(
            connector=connector,
            timeout=timeout
        ) as session:
            
            tasks = []
            start_time = time.time()
            
            # é˜¶æ®µ1: çˆ¬å¡é˜¶æ®µ - é€æ¸å¢åŠ ç”¨æˆ·
            print(f"ğŸ“ˆ é˜¶æ®µ1: çˆ¬å¡é˜¶æ®µ ({ramp_up_time}ç§’)")
            for i in range(target_users):
                # è®¡ç®—ç”¨æˆ·å¯åŠ¨æ—¶é—´
                user_start_delay = (i / target_users) * ramp_up_time
                
                # åˆ›å»ºç”¨æˆ·ä¼šè¯ä»»åŠ¡
                task = asyncio.create_task(
                    self.delayed_user_session(session, i, user_start_delay, test_duration)
                )
                tasks.append(task)
                
                # å®æ—¶æ˜¾ç¤ºè¿›åº¦
                if i % 50 == 0:
                    print(f"   å·²åˆ›å»º {i} ä¸ªç”¨æˆ·ä»»åŠ¡...")
            
            print(f"âœ… æ‰€æœ‰ {target_users} ä¸ªç”¨æˆ·ä»»åŠ¡å·²åˆ›å»º")
            
            # é˜¶æ®µ2: ç›‘æ§é˜¶æ®µ
            print(f"ğŸ“Š é˜¶æ®µ2: ç›‘æ§é˜¶æ®µ")
            monitor_interval = 5  # æ¯5ç§’ç›‘æ§ä¸€æ¬¡
            total_test_time = ramp_up_time + test_duration
            
            while time.time() - start_time < total_test_time:
                await asyncio.sleep(monitor_interval)
                elapsed = time.time() - start_time
                print(f"   æ—¶é—´: {elapsed:.1f}s | å½“å‰å¹¶å‘ç”¨æˆ·: {self.active_users} | å³°å€¼å¹¶å‘: {self.max_concurrent_users}")
            
            # é˜¶æ®µ3: ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
            print(f"â³ é˜¶æ®µ3: ç­‰å¾…æ‰€æœ‰ç”¨æˆ·ä¼šè¯ç»“æŸ...")
            all_results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # æ”¶é›†æ‰€æœ‰ç»“æœ
            for user_results in all_results:
                if isinstance(user_results, list):
                    self.results.extend(user_results)
                elif isinstance(user_results, dict):
                    self.results.append(user_results)
        
        print(f"âœ… å¹¶å‘æµ‹è¯•å®Œæˆ")
        print(f"   å³°å€¼å¹¶å‘ç”¨æˆ·æ•°: {self.max_concurrent_users}")
        print(f"   æ”¶é›†åˆ°çš„è¯·æ±‚æ•°: {len(self.results)}")
    
    async def delayed_user_session(self, session, user_id, delay, duration):
        """å»¶è¿Ÿå¯åŠ¨çš„ç”¨æˆ·ä¼šè¯"""
        # ç­‰å¾…åˆ°æŒ‡å®šçš„å¯åŠ¨æ—¶é—´
        await asyncio.sleep(delay)
        
        # å¼€å§‹ç”¨æˆ·ä¼šè¯
        return await self.simulate_user_session(session, user_id, duration)
    
    def analyze_concurrent_results(self):
        """åˆ†æå¹¶å‘æµ‹è¯•ç»“æœ"""
        if not self.results:
            print("âŒ æ²¡æœ‰æµ‹è¯•ç»“æœå¯åˆ†æ")
            return None
        
        # åŸºç¡€ç»Ÿè®¡
        successful_requests = [r for r in self.results if r.get('success', False)]
        failed_requests = [r for r in self.results if not r.get('success', False)]
        
        if not successful_requests:
            print("âŒ æ²¡æœ‰æˆåŠŸçš„è¯·æ±‚")
            return None
        
        # å“åº”æ—¶é—´ç»Ÿè®¡
        response_times = [r['response_time'] for r in successful_requests]
        
        # å¹¶å‘ç”¨æˆ·ç»Ÿè®¡
        unique_users = len(set(r.get('user_id', 0) for r in self.results))
        
        # æŒ‰æ—¶é—´æ®µåˆ†æå¹¶å‘åº¦
        time_buckets = {}
        for result in self.results:
            timestamp = result.get('timestamp', '')
            if timestamp:
                # æŒ‰åˆ†é’Ÿåˆ†ç»„
                minute_key = timestamp[:16]  # YYYY-MM-DDTHH:MM
                if minute_key not in time_buckets:
                    time_buckets[minute_key] = set()
                time_buckets[minute_key].add(result.get('user_id', 0))
        
        # è®¡ç®—æ¯åˆ†é’Ÿçš„å¹¶å‘ç”¨æˆ·æ•°
        concurrent_users_per_minute = {k: len(v) for k, v in time_buckets.items()}
        avg_concurrent_users = statistics.mean(concurrent_users_per_minute.values()) if concurrent_users_per_minute else 0
        
        analysis = {
            'total_requests': len(self.results),
            'successful_requests': len(successful_requests),
            'failed_requests': len(failed_requests),
            'success_rate': len(successful_requests) / len(self.results) * 100,
            'unique_users': unique_users,
            'max_concurrent_users': self.max_concurrent_users,
            'avg_concurrent_users': avg_concurrent_users,
            'average_response_time': statistics.mean(response_times),
            'median_response_time': statistics.median(response_times),
            'min_response_time': min(response_times),
            'max_response_time': max(response_times),
            'p95_response_time': self.percentile(response_times, 95),
            'p99_response_time': self.percentile(response_times, 99),
            'concurrent_users_per_minute': concurrent_users_per_minute
        }
        
        # æŒ‰ç«¯ç‚¹åˆ†æ
        endpoint_stats = {}
        for result in successful_requests:
            endpoint = result['endpoint']
            if endpoint not in endpoint_stats:
                endpoint_stats[endpoint] = []
            endpoint_stats[endpoint].append(result['response_time'])
        
        analysis['endpoint_stats'] = {}
        for endpoint, times in endpoint_stats.items():
            analysis['endpoint_stats'][endpoint] = {
                'count': len(times),
                'average': statistics.mean(times),
                'min': min(times),
                'max': max(times)
            }
        
        return analysis
    
    def percentile(self, data, percentile):
        """è®¡ç®—ç™¾åˆ†ä½æ•°"""
        sorted_data = sorted(data)
        index = (percentile / 100) * (len(sorted_data) - 1)
        lower = int(index)
        upper = min(lower + 1, len(sorted_data) - 1)
        weight = index - lower
        return sorted_data[lower] * (1 - weight) + sorted_data[upper] * weight
    
    def generate_concurrent_report(self, analysis, output_file="concurrent_report.md"):
        """ç”Ÿæˆå¹¶å‘æµ‹è¯•æŠ¥å‘Š"""
        if not analysis:
            return
        
        report_content = f"""# ğŸš€ èƒ½æºäº¤æ˜“å¹³å°å¹¶å‘æµ‹è¯•æŠ¥å‘Š

## ğŸ“Š æµ‹è¯•æ¦‚è§ˆ

- **æµ‹è¯•æ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **æµ‹è¯•ç›®æ ‡**: å¹¶å‘ç”¨æˆ·æ•° > 200
- **å®é™…å³°å€¼å¹¶å‘ç”¨æˆ·æ•°**: {analysis['max_concurrent_users']}
- **å¹³å‡å¹¶å‘ç”¨æˆ·æ•°**: {analysis['avg_concurrent_users']:.1f}
- **æ€»è¯·æ±‚æ•°**: {analysis['total_requests']}
- **æˆåŠŸè¯·æ±‚æ•°**: {analysis['successful_requests']}
- **å¤±è´¥è¯·æ±‚æ•°**: {analysis['failed_requests']}
- **æˆåŠŸç‡**: {analysis['success_rate']:.2f}%

## ğŸ¯ å¹¶å‘æ€§èƒ½æŒ‡æ ‡

| æŒ‡æ ‡ | æ•°å€¼ | ç›®æ ‡ | çŠ¶æ€ |
|------|------|------|------|
| å³°å€¼å¹¶å‘ç”¨æˆ·æ•° | {analysis['max_concurrent_users']} | > 200 | {'âœ… é€šè¿‡' if analysis['max_concurrent_users'] > 200 else 'âŒ æœªé€šè¿‡'} |
| å¹³å‡å¹¶å‘ç”¨æˆ·æ•° | {analysis['avg_concurrent_users']:.1f} | - | - |
| æ€»ç”¨æˆ·æ•° | {analysis['unique_users']} | - | - |
| ç³»ç»ŸæˆåŠŸç‡ | {analysis['success_rate']:.2f}% | > 95% | {'âœ… è‰¯å¥½' if analysis['success_rate'] > 95 else 'âš ï¸ éœ€è¦æ”¹è¿›'} |

## â±ï¸ é«˜å¹¶å‘ä¸‹çš„å“åº”æ—¶é—´

| æŒ‡æ ‡ | æ•°å€¼ | çŠ¶æ€ |
|------|------|------|
| å¹³å‡å“åº”æ—¶é—´ | {analysis['average_response_time']:.3f}s | {'âœ… è‰¯å¥½' if analysis['average_response_time'] < 5 else 'âš ï¸ éœ€è¦ä¼˜åŒ–'} |
| ä¸­ä½æ•°å“åº”æ—¶é—´ | {analysis['median_response_time']:.3f}s | - |
| æœ€å°å“åº”æ—¶é—´ | {analysis['min_response_time']:.3f}s | - |
| æœ€å¤§å“åº”æ—¶é—´ | {analysis['max_response_time']:.3f}s | {'âœ… å¯æ¥å—' if analysis['max_response_time'] < 30 else 'âŒ è¿‡é•¿'} |
| P95å“åº”æ—¶é—´ | {analysis['p95_response_time']:.3f}s | {'âœ… è‰¯å¥½' if analysis['p95_response_time'] < 10 else 'âš ï¸ éœ€è¦ä¼˜åŒ–'} |
| P99å“åº”æ—¶é—´ | {analysis['p99_response_time']:.3f}s | {'âœ… è‰¯å¥½' if analysis['p99_response_time'] < 15 else 'âš ï¸ éœ€è¦ä¼˜åŒ–'} |

## ğŸ“ˆ å„ç«¯ç‚¹å¹¶å‘æ€§èƒ½

| ç«¯ç‚¹ | è¯·æ±‚æ•° | å¹³å‡å“åº”æ—¶é—´ | æœ€å°æ—¶é—´ | æœ€å¤§æ—¶é—´ | çŠ¶æ€ |
|------|--------|--------------|----------|----------|------|
"""
        
        for endpoint, stats in analysis['endpoint_stats'].items():
            status = 'âœ… è‰¯å¥½' if stats['average'] < 5 else ('âš ï¸ ä¸€èˆ¬' if stats['average'] < 10 else 'âŒ è¾ƒæ…¢')
            report_content += f"| {endpoint} | {stats['count']} | {stats['average']:.3f}s | {stats['min']:.3f}s | {stats['max']:.3f}s | {status} |\n"
        
        # å¹¶å‘ç”¨æˆ·æ•°æ—¶é—´åˆ†å¸ƒ
        if analysis['concurrent_users_per_minute']:
            report_content += f"""
## ğŸ“Š å¹¶å‘ç”¨æˆ·æ•°æ—¶é—´åˆ†å¸ƒ

| æ—¶é—´ç‚¹ | å¹¶å‘ç”¨æˆ·æ•° |
|--------|------------|
"""
            for time_point, user_count in sorted(analysis['concurrent_users_per_minute'].items()):
                report_content += f"| {time_point} | {user_count} |\n"
        
        report_content += f"""
## ğŸ¯ æµ‹è¯•ç»“è®º

### å¹¶å‘ç›®æ ‡è¾¾æˆæƒ…å†µ
- **å¹¶å‘ç”¨æˆ·æ•°ç›®æ ‡**: {'âœ… è¾¾æˆ' if analysis['max_concurrent_users'] > 200 else 'âŒ æœªè¾¾æˆ'}
- **ç³»ç»Ÿç¨³å®šæ€§**: {'âœ… è‰¯å¥½' if analysis['success_rate'] > 95 else 'âš ï¸ éœ€è¦æ”¹è¿›'}
- **å“åº”æ€§èƒ½**: {'âœ… è‰¯å¥½' if analysis['average_response_time'] < 5 else 'âš ï¸ éœ€è¦ä¼˜åŒ–'}

### æ€§èƒ½è¯„ä¼°
"""
        
        if analysis['max_concurrent_users'] <= 200:
            report_content += "- âŒ æœªè¾¾åˆ°200å¹¶å‘ç”¨æˆ·ç›®æ ‡ï¼Œå»ºè®®ä¼˜åŒ–æœåŠ¡å™¨é…ç½®å’Œæ•°æ®åº“è¿æ¥æ± \n"
        else:
            report_content += f"- âœ… æˆåŠŸæ”¯æŒ {analysis['max_concurrent_users']} å¹¶å‘ç”¨æˆ·\n"
        
        if analysis['success_rate'] < 95:
            report_content += "- âš ï¸ é«˜å¹¶å‘ä¸‹æˆåŠŸç‡ä½äº95%ï¼Œå»ºè®®æ£€æŸ¥é”™è¯¯å¤„ç†å’Œèµ„æºé™åˆ¶\n"
        
        if analysis['average_response_time'] > 5:
            report_content += "- âš ï¸ é«˜å¹¶å‘ä¸‹å¹³å‡å“åº”æ—¶é—´è¿‡é•¿ï¼Œå»ºè®®ä¼˜åŒ–æ•°æ®åº“æŸ¥è¯¢å’Œç¼“å­˜ç­–ç•¥\n"
        
        if analysis['max_response_time'] > 30:
            report_content += "- âš ï¸ æœ€å¤§å“åº”æ—¶é—´è¿‡é•¿ï¼Œå»ºè®®æ·»åŠ è¯·æ±‚è¶…æ—¶å’Œè´Ÿè½½å‡è¡¡\n"
        
        if (analysis['max_concurrent_users'] > 200 and 
            analysis['success_rate'] > 95 and 
            analysis['average_response_time'] < 5):
            report_content += "- âœ… ç³»ç»Ÿå¹¶å‘æ€§èƒ½è¡¨ç°ä¼˜ç§€ï¼Œæ»¡è¶³é«˜å¹¶å‘è¦æ±‚\n"
        
        report_content += f"""
## ğŸ“ è¯¦ç»†æ•°æ®

### æµ‹è¯•é…ç½®
- ç›®æ ‡å¹¶å‘ç”¨æˆ·æ•°: > 200
- å®é™…æµ‹è¯•ç”¨æˆ·æ•°: {analysis['unique_users']}
- å³°å€¼å¹¶å‘ç”¨æˆ·æ•°: {analysis['max_concurrent_users']}
- æ€»è¯·æ±‚æ•°: {analysis['total_requests']}

---
*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
"""
        
        # ä¿å­˜æŠ¥å‘Š
        os.makedirs('tests/reports', exist_ok=True)
        report_path = f"tests/reports/{output_file}"
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        print(f"ğŸ“„ å¹¶å‘æµ‹è¯•æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
        return report_path
    
    def save_concurrent_raw_data(self, filename="concurrent_raw_data.csv"):
        """ä¿å­˜åŸå§‹å¹¶å‘æµ‹è¯•æ•°æ®"""
        os.makedirs('tests/reports', exist_ok=True)
        csv_path = f"tests/reports/{filename}"
        
        with open(csv_path, 'w', newline='', encoding='utf-8') as csvfile:
            fieldnames = ['timestamp', 'user_id', 'endpoint', 'method', 'response_time', 'status', 'success']
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            
            writer.writeheader()
            for result in self.results:
                writer.writerow({
                    'timestamp': result.get('timestamp', ''),
                    'user_id': result.get('user_id', ''),
                    'endpoint': result.get('endpoint', ''),
                    'method': result.get('method', ''),
                    'response_time': result.get('response_time', 0),
                    'status': result.get('status', 0),
                    'success': result.get('success', False)
                })
        
        print(f"ğŸ’¾ åŸå§‹å¹¶å‘æ•°æ®å·²ä¿å­˜: {csv_path}")

async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ èƒ½æºäº¤æ˜“å¹³å°å¹¶å‘æµ‹è¯•")
    print("=" * 50)
    
    tester = ConcurrentTest()
    
    # è¿è¡Œå¹¶å‘æµ‹è¯• (ç›®æ ‡250ç”¨æˆ·ï¼Œ30ç§’çˆ¬å¡ï¼Œ120ç§’æµ‹è¯•)
    await tester.run_concurrent_test(
        target_users=250, 
        ramp_up_time=30, 
        test_duration=120
    )
    
    # åˆ†æç»“æœ
    analysis = tester.analyze_concurrent_results()
    
    if analysis:
        # ç”ŸæˆæŠ¥å‘Š
        tester.generate_concurrent_report(analysis)
        tester.save_concurrent_raw_data()
        
        # æ‰“å°å…³é”®æŒ‡æ ‡
        print("\nğŸ“Š å…³é”®å¹¶å‘æŒ‡æ ‡:")
        print(f"   å³°å€¼å¹¶å‘ç”¨æˆ·æ•°: {analysis['max_concurrent_users']}")
        print(f"   å¹³å‡å¹¶å‘ç”¨æˆ·æ•°: {analysis['avg_concurrent_users']:.1f}")
        print(f"   æˆåŠŸç‡: {analysis['success_rate']:.2f}%")
        print(f"   å¹³å‡å“åº”æ—¶é—´: {analysis['average_response_time']:.3f}s")
        
        # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°ç›®æ ‡
        if analysis['max_concurrent_users'] > 200:
            print("   âœ… å¹¶å‘ç›®æ ‡è¾¾æˆï¼")
        else:
            print("   âŒ å¹¶å‘ç›®æ ‡æœªè¾¾æˆ")

if __name__ == "__main__":
    asyncio.run(main()) 